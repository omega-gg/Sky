diff --git a/src/config/argument_config.py b/src/config/argument_config.py
index 055f5f8..9849836 100644
--- a/src/config/argument_config.py
+++ b/src/config/argument_config.py
@@ -41,7 +41,7 @@ class ArgumentConfig(PrintableConfig):
     vx_ratio: float = 0  # the ratio to move the face to left or right in cropping space
     vy_ratio: float = -0.125  # the ratio to move the face to up or down in cropping space
     flag_do_rot: bool = True  # whether to conduct the rotation when flag_do_crop is True
-    source_max_dim: int = 1280 # the max dim of height and width of source image or video, you can change it to a larger number, e.g., 1920
+    source_max_dim: int = 3840 # the max dim of height and width of source image or video, you can change it to a larger number, e.g., 1920
     source_division: int = 2 # make sure the height and width of source image or video can be divided by this number
 
     ########## driving crop arguments ##########
diff --git a/src/config/inference_config.py b/src/config/inference_config.py
index 2d9f365..be82eaa 100644
--- a/src/config/inference_config.py
+++ b/src/config/inference_config.py
@@ -52,7 +52,7 @@ class InferenceConfig(PrintableConfig):
     driving_option: str = "pose-friendly" # "expression-friendly" or "pose-friendly"
     driving_multiplier: float = 1.0
     driving_smooth_observation_variance: float = 3e-7 # smooth strength scalar for the animated video when the input is a source video, the larger the number, the smoother the animated video; too much smoothness would result in loss of motion accuracy
-    source_max_dim: int = 1280 # the max dim of height and width of source image or video
+    source_max_dim: int = 3840 # the max dim of height and width of source image or video
     source_division: int = 2 # make sure the height and width of source image or video can be divided by this number
     animation_region: Literal["exp", "pose", "lip", "eyes", "all"] = "all" # the region where the animation was performed, "exp" means the expression, "pose" means the head pose
 
diff --git a/src/gradio_pipeline.py b/src/gradio_pipeline.py
index 4ccd951..7110c53 100644
--- a/src/gradio_pipeline.py
+++ b/src/gradio_pipeline.py
@@ -348,7 +348,7 @@ class GradioPipeline(LivePortraitPipeline):
             self.cropper.update_config(self.args.__dict__)
             inference_cfg = self.live_portrait_wrapper.inference_cfg
             ######## process source portrait ########
-            img_rgb = load_img_online(input_image, mode='rgb', max_dim=1280, n=2)
+            img_rgb = load_img_online(input_image, mode='rgb', max_dim=3840, n=2)
             if flag_do_crop:
                 crop_info = self.cropper.crop_source_image(img_rgb, self.cropper.crop_cfg)
                 I_s = self.live_portrait_wrapper.prepare_source(crop_info['img_crop_256x256'])
@@ -383,7 +383,7 @@ class GradioPipeline(LivePortraitPipeline):
             self.cropper.update_config(self.args.__dict__)
             # inference_cfg = self.live_portrait_wrapper.inference_cfg
             ######## process source portrait ########
-            img_rgb = load_img_online(input_image, mode='rgb', max_dim=1280, n=16)
+            img_rgb = load_img_online(input_image, mode='rgb', max_dim=3840, n=16)
             log(f"Load source image from {input_image}.")
             crop_info = self.cropper.crop_source_image(img_rgb, self.cropper.crop_cfg)
             if crop_info is None:
diff --git a/src/utils/io.py b/src/utils/io.py
index 9e4bc69..229533b 100644
--- a/src/utils/io.py
+++ b/src/utils/io.py
@@ -35,7 +35,7 @@ def contiguous(obj):
     return obj
 
 
-def resize_to_limit(img: np.ndarray, max_dim=1920, division=2):
+def resize_to_limit(img: np.ndarray, max_dim=3840, division=2):
     """
     ajust the size of the image so that the maximum dimension does not exceed max_dim, and the width and the height of the image are multiples of n.
     :param img: the image to be processed.
@@ -71,7 +71,7 @@ def resize_to_limit(img: np.ndarray, max_dim=1920, division=2):
 
 
 def load_img_online(obj, mode="bgr", **kwargs):
-    max_dim = kwargs.get("max_dim", 1920)
+    max_dim = kwargs.get("max_dim", 3840)
     n = kwargs.get("n", 2)
     if isinstance(obj, str):
         if mode.lower() == "gray":
diff --git a/src/utils/video.py b/src/utils/video.py
index 2e34e6d..f8340e8 100644
--- a/src/utils/video.py
+++ b/src/utils/video.py
@@ -30,7 +30,7 @@ def images2video(images, wfp, **kwargs):
     pixelformat = kwargs.get('pixelformat', 'yuv420p')  # video pixel format
     image_mode = kwargs.get('image_mode', 'rgb')
     macro_block_size = kwargs.get('macro_block_size', 2)
-    ffmpeg_params = ['-crf', str(kwargs.get('crf', 18))]
+    ffmpeg_params = ['-crf', str(kwargs.get('crf', 15))]
 
     writer = imageio.get_writer(
         wfp, fps=fps, format=video_format,
